{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T12:38:51.206324Z",
     "start_time": "2025-03-31T12:38:51.036004Z"
    }
   },
   "source": [
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(open(\"weather.html\"), \"html.parser\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Weather Forecast\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h4>\n",
      "   5-Day Weather Forecast\n",
      "  </h4>\n",
      "  <table>\n",
      "   <thead>\n",
      "    <tr>\n",
      "     <th>\n",
      "      Day\n",
      "     </th>\n",
      "     <th>\n",
      "      Temperature\n",
      "     </th>\n",
      "     <th>\n",
      "      Condition\n",
      "     </th>\n",
      "    </tr>\n",
      "   </thead>\n",
      "   <tbody>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Monday\n",
      "     </td>\n",
      "     <td>\n",
      "      25°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Sunny\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Tuesday\n",
      "     </td>\n",
      "     <td>\n",
      "      22°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Cloudy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Wednesday\n",
      "     </td>\n",
      "     <td>\n",
      "      18°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Rainy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Thursday\n",
      "     </td>\n",
      "     <td>\n",
      "      20°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Partly Cloudy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      Friday\n",
      "     </td>\n",
      "     <td>\n",
      "      30°C\n",
      "     </td>\n",
      "     <td>\n",
      "      Sunny\n",
      "     </td>\n",
      "    </tr>\n",
      "   </tbody>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T12:53:29.182937Z",
     "start_time": "2025-03-31T12:53:29.175024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "datas=soup.find_all(\"tr\")\n",
    "for data in datas:\n",
    "    details=data.find_all(\"td\")\n",
    "\n",
    "    for detail in details:\n",
    "         print(detail.text)\n",
    "\n"
   ],
   "id": "7cc90e55ea03bde6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday\n",
      "25°C\n",
      "Sunny\n",
      "Tuesday\n",
      "22°C\n",
      "Cloudy\n",
      "Wednesday\n",
      "18°C\n",
      "Rainy\n",
      "Thursday\n",
      "20°C\n",
      "Partly Cloudy\n",
      "Friday\n",
      "30°C\n",
      "Sunny\n",
      "{}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:24:06.391958Z",
     "start_time": "2025-03-31T13:24:06.325981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def highesttemp():\n",
    "    information={}\n",
    "\n",
    "    list=[]\n",
    "    soup=BeautifulSoup(open(\"weather.html\"), \"html.parser\")\n",
    "    bodies=soup.find_all(\"tbody\")\n",
    "    for body in bodies:\n",
    "        datas=body.find_all(\"tr\")\n",
    "        for data in datas:\n",
    "            details=data.find_all(\"td\")\n",
    "            for detail in details:\n",
    "                list.append(detail.text)\n",
    "            information[list[0]]=list\n",
    "            list=[]\n",
    "    values=list[information.values()]\n",
    "    keys=list(information.keys())\n",
    "    for cur,next in zip(values,values[1:]):\n",
    "        temp=cur[1]\n",
    "        if temp>next[1]:\n",
    "            maxtemp=temp\n",
    "            thatday=keys[cur[0]]\n",
    "        elif temp<next[1]:\n",
    "            maxtemp=next[1]\n",
    "            day=keys[next[0]]\n",
    "    print(maxtemp)\n",
    "    print(information)\n",
    "\n",
    "highesttemp()"
   ],
   "id": "b8edbc5014899f9",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not dict_values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 28\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;28mprint\u001B[39m(maxtemp)\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28mprint\u001B[39m(information)\n\u001B[0;32m---> 28\u001B[0m \u001B[43mhighesttemp\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[41], line 15\u001B[0m, in \u001B[0;36mhighesttemp\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m         information[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m\n\u001B[1;32m     14\u001B[0m         \u001B[38;5;28mlist\u001B[39m\u001B[38;5;241m=\u001B[39m[]\n\u001B[0;32m---> 15\u001B[0m values\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43minformation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     16\u001B[0m keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlist\u001B[39m(information\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cur,\u001B[38;5;28mnext\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(values,values[\u001B[38;5;241m1\u001B[39m:]):\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not dict_values"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:21:27.516546Z",
     "start_time": "2025-03-31T13:21:27.504016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def averagetemp():\n",
    "    information={}\n",
    "    totaltemp=0\n",
    "    counter=0\n",
    "    list=[]\n",
    "\n",
    "    soup=BeautifulSoup(open(\"weather.html\"), \"html.parser\")\n",
    "    bodies=soup.find_all(\"tbody\")\n",
    "    for body in bodies:\n",
    "        datas=body.find_all(\"tr\")\n",
    "        for data in datas:\n",
    "            details=data.find_all(\"td\")\n",
    "            for detail in details:\n",
    "                list.append(detail.text)\n",
    "            information[list[0]]=list\n",
    "            list=[]\n",
    "    print(information)\n",
    "    for days in information:\n",
    "        totaltemp+=int(information[days][1][0:len(information[days][1])-2])\n",
    "        counter+=1\n",
    "        print(totaltemp)\n",
    "    return(totaltemp/counter)\n",
    "averagetemp()\n"
   ],
   "id": "98d481c8c32985c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Monday': ['Monday', '25°C', 'Sunny'], 'Tuesday': ['Tuesday', '22°C', 'Cloudy'], 'Wednesday': ['Wednesday', '18°C', 'Rainy'], 'Thursday': ['Thursday', '20°C', 'Partly Cloudy'], 'Friday': ['Friday', '30°C', 'Sunny']}\n",
      "25\n",
      "47\n",
      "65\n",
      "85\n",
      "115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:23:54.678876Z",
     "start_time": "2025-03-31T13:23:54.647983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sunny():\n",
    "    information={}\n",
    "    list=[]\n",
    "    soup=BeautifulSoup(open(\"weather.html\"), \"html.parser\")\n",
    "    bodies=soup.find_all(\"tbody\")\n",
    "    for body in bodies:\n",
    "        datas=body.find_all(\"tr\")\n",
    "        for data in datas:\n",
    "            details=data.find_all(\"td\")\n",
    "            for detail in details:\n",
    "                list.append(detail.text)\n",
    "            information[list[0]]=list\n",
    "            list=[]\n",
    "    for days in information:\n",
    "        if information[days][2]==\"Sunny\":\n",
    "            print(information[days][0])\n",
    "sunny()"
   ],
   "id": "ca40beaf53f27b7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday\n",
      "Friday\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:50:28.451913Z",
     "start_time": "2025-04-02T16:50:22.037103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "namess=[]\n",
    "positionss=[]\n",
    "locationss=[]\n",
    "url =\"https://realpython.github.io/fake-jobs\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "containers=soup.find_all('div',class_='card-content')\n",
    "connector=sqlite3.connect('jobs.db')\n",
    "cursor=connector.cursor()\n",
    "# cursor.execute(\"Create table Jobs(Position text,name text, Location text, Details text,Applylink text\")\n",
    "for container in containers:\n",
    "    position=container.find('h2').text\n",
    "    name=container.find('h3').text\n",
    "    location = container.find('p', class_=\"location\").text\n",
    "    detail_url=container.find('a',string=\"Learn\")['href']\n",
    "    # detailresponse=requests.get(detail_url)\n",
    "    # detailsoup=BeautifulSoup(detailresponse.content, \"html.parser\")\n",
    "    # detailcontent=detailsoup.find('p').text.strip()\n",
    "    detailcon=\"In this tutorial, you'll learn about Python's bytearray, a mutable sequence of bytes for efficient binary data manipulation. You'll explore how it differs from bytes, how to create and modify bytearray objects, and when to use them in tasks like processing binary files and network protocols.\"\n",
    "\n",
    "    apply_url=container.find('a',string=\"Apply\")['href']\n",
    "    cursor.execute(\n",
    "        '''\n",
    "        INSERT INTO Jobs(Position,Name,Location,Details,Applylink) values(?,?,?,?,?)''',\n",
    "        (position,name,location,detailcon,apply_url)\n",
    "    )\n",
    "\n",
    "\n",
    "connector.commit()\n",
    "connector.close()\n",
    "def filterbylocation():\n",
    "    information={}\n",
    "    list=[]\n",
    "    with sqlite3.connect('jobs.db') as connector:\n",
    "        cursor=connector.cursor()\n",
    "        cursor.execute(\"SELECT * FROM Jobs order by Name asc\")\n",
    "        for row in cursor:\n",
    "            list.append(row)\n",
    "    with open('jobs.csv','w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Job Title\", \"Company Name\", \"Location\", \"Description\", \"Application Link\"])\n",
    "        writer.writerows(list)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "192d01de5010404a",
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[133], line 24\u001B[0m\n\u001B[1;32m     21\u001B[0m     detailcon\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn this tutorial, you\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mll learn about Python\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms bytearray, a mutable sequence of bytes for efficient binary data manipulation. You\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mll explore how it differs from bytes, how to create and modify bytearray objects, and when to use them in tasks like processing binary files and network protocols.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     23\u001B[0m     apply_url\u001B[38;5;241m=\u001B[39mcontainer\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m,string\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mApply\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhref\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 24\u001B[0m     \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;250;43m        \u001B[39;49m\u001B[38;5;124;43;03m'''\u001B[39;49;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;43;03m        INSERT INTO Jobs(Position,Name,Location,Details,Applylink) values(?,?,?,?,?)'''\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[43mposition\u001B[49m\u001B[43m,\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdetailcon\u001B[49m\u001B[43m,\u001B[49m\u001B[43mapply_url\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m connector\u001B[38;5;241m.\u001B[39mcommit()\n\u001B[1;32m     32\u001B[0m connector\u001B[38;5;241m.\u001B[39mclose()\n",
      "\u001B[0;31mOperationalError\u001B[0m: database is locked"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T16:44:19.933127Z",
     "start_time": "2025-04-02T16:44:18.979711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Url=\"https://www.demoblaze.com/#\"\n",
    "response = requests.get(Url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "containers=soup.find_all('h4')\n",
    "for container in containers:\n",
    "    print(container)\n",
    "    break\n",
    "print(containers)\n"
   ],
   "id": "a64a967cce133f65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h4 class=\"grrrr\"><b>About Us</b></h4>\n",
      "[<h4 class=\"grrrr\"><b>About Us</b></h4>, <h4 class=\"grrrr\"><b>Get in Touch</b></h4>, <h4><img height=\"50\" src=\"bm.png\" style=\"margin-right:10px\" width=\"50\"/> PRODUCT STORE</h4>]\n"
     ]
    }
   ],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "921c9610c7ae8a9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
